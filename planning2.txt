Remove acustic and intrumentalness 

Enhanced model with discrete 

For binary:


For transformation- take the listen count into

log likelyhood at given observation (song feature point)

Put the 


If he wants to keep giving recomendation 
user wants a song- sample from the 


#next steps
0.5 Build a frame with recs
1. Build a dataframe that calculated P and recall
- Content
- Colab
2. Look at the feature dist of songs listening too vs predicted
3. Add depht to feature songs for listen count
4. Build a hybrid thats weighted for both
5. 


Conc1:
It all comes down to the method, this song will fit my dist
it's just a matter of how good my dist are from the 
begining

-- Visuals
#Get the scatterplot of where the top songs
are located
#Put the top predictions on the scatter plot


First 10 songs 
For given user remove all songs that he don't listen
Three bar
Blue - popular songs
Green - liklelyhood of that song (his 10 songs)/total likelyhood
Blue - the top10 listened songs overall (then take the songs of those he listened too)
(that song/total listens)

Talk about how to further expand the model 

real value:
Listen count of that song/total_listen count

Rec:
Likelyhood of this song/tot likelyhood for all user_top10

Colab filt:
Use predicted rating for given user/all predicted counts

Then compute difference between the real and the pred 


Baseline:
top10_user - how often are they listened to general public = x
x / total listen count - then if he listens to the general public

Analysis if the baseline shows bad results - then there is a need for
personal recomendation to begin in. 


MEETING: 

Get mse for all users 
Plot - the MSE for all users

if still error we can say that user tend to listen to more popular songs
only listens to their friends

is there a group where there is a difference

divide the users into good and bad
Divide based on the big difference

If we have a stable group, do some cross validation and see if it works

mahalanobis distance- square it 
is in theory a X^2 dist with p dof (p=nr of feats)

split into k rings (maybe 5)
c_i = percentage for the quantile:
	(k-i)/k where I is the current ring

in r: you would do 
quant.xsquare(4/5) (the 4th quanrantile out of the 5)


model user base
5%	10%	1%
5%
5%

Take each points and evaluate how many times it appears 

1. Calc c (decide how many bins) and how many to compare
	Check a chi square with 8 dOf
2. what is the 1st,2nd third quarentile in chi-squared
	These values will be the boarder
3. Set the interval
3.5 (calc the distance, no need to take listen count into here)
4. Count how many songs that appear in the interval
	If the song is here, whats the listen count
	Whats the general count
5. Get the count for general (base) and user
6. Divide by total listen count for user and total count for public (in test)




#To get a good feel for colab
- just check how it performs on unpopular songs and talk about how 
this should be adressed by content